{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c51efaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4acf73a0-51b5-4663-9bb8-8eb947863e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef880a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7836ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c08294",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4854399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669fda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf532ae7-1897-428c-ba0c-875ccaf7d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of predictions: 6.25\n"
     ]
    }
   ],
   "source": [
    "# Q1. What's the standard deviation of the predicted duration for this dataset?\n",
    "\n",
    "print(f\"Standard deviation of predictions: {round(y_pred.std(axis=0), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd76a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "month = 3\n",
    "\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7866aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(data={\"ride_id\": df['ride_id'], \"predictions\": y_pred})\n",
    "output_file = \"predictions.parquet\"\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f11594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66M predictions.parquet\n"
     ]
    }
   ],
   "source": [
    "# Q2. What's the size of the output file\n",
    "\n",
    "!ls -sh $output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Creating the scoring script\n",
    "# jupyter nbconvert --to script starter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47881858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mInstalling scikit-\u001b[0m\u001b[1;33mlearn\u001b[0m\u001b[1;32m==\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;32m.\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving scikit-\u001b[33mlearn\u001b[0m==\u001b[1;36m1.5\u001b[0m.\u001b[1;36m0\u001b[0m\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeeded\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing scikit-learn...\n",
      "\u001b[1A\u001b[2K\u001b[1;32mInstalling pyarrow\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving pyarrow\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeeded\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing pyarrow...\n",
      "\u001b[1A\u001b[2K\u001b[1;32mInstalling pandas\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving pandas\u001b[33m...\u001b[0m\n",
      "\u001b[2K\u001b[1mAdded \u001b[0m\u001b[1;32mpandas\u001b[0m to Pipfile's \u001b[1;33m[\u001b[0m\u001b[33mpackages\u001b[0m\u001b[1;33m]\u001b[0m \u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeeded...\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing pandas...\n",
      "\u001b[1A\u001b[2K\u001b[1;33mPipfile.lock \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mc38461\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m out of date, updating to \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m3c2ffe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "Locking\u001b[0m \u001b[33m[packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking...\n",
      "\u001b[2K\u001b[32m⠧\u001b[0m Locking...\n",
      "\u001b[1A\u001b[2KLocking\u001b[0m \u001b[33m[dev-packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[1mUpdated Pipfile.lock (2781451e8c683e398151f1d8c3d80084214c5cb95e0d9a8227dc69bc2f3c2ffe)!\u001b[0m\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1m3c2ffe\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "# Q4\n",
    "!pipenv install scikit-learn==1.5.0 pyarrow pandas --python=3.10\n",
    "\n",
    "# What's the first hash for the Scikit-Learn dependency? \"sha256:057b991ac64b3e75c9c04b5f9395eaf19a6179244c089afdebaad98264bff37c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee364b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "reading file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet\n",
      "applying model\n",
      "saving predictions\n",
      "Mean of predictions: 14.29\n"
     ]
    }
   ],
   "source": [
    "# Q5 Parametrize the script\n",
    "!pipenv run python starter.py yellow 2023 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10adf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
